################### Experiment information ######################
description: end-to-end version of protoEFnet model 
run_name: "ProtoEFNet_Video"
agent: "Video_protoEF_e2e"
wandb_mode: 'online'  # one of "online", "offline" or "disabled". disabled turns wandb logging off! good for testing
abstain_class: False

################## Model information ##########################
model: &model
  checkpoint_path: ''
  name: "Video_protoEF"
  base_architecture: 'resnet2p1d_18'  # backbone
  backbone_last_layer_num: -3 # Either -2 or -3
  pretrained: True
  prototype_shape: (40, 256, 1, 1, 1)  # either 512 or 256, output size is 7,7, this here is the total number of prototypes.
  similarity_metric: "cosine" # chose from cosine and l2
  init_weights: True
  init_ll: "ones" # class_idx or ones
  prototype_activation_function: "linear" # not used in the current code
  fc_method: "soft_attention" # chose from weighted_sum, soft_attention
  tau: 0.2
  proto_minrange: 10.0
  proto_maxrange: 90.0
  num_classes: 1 # regression 
  #push_at_end: False
  #push_only: True 
  #eval_only: True

################## Training information ##########################
train: &train
  seed: 200
  num_train_epochs: 30
  save: True
  save_step: 10
  num_warm_epochs: 30
  finetune_after_push: True
  batch_size: 16
  accumulation_steps: 1
  push_start: 30
  push_rate: 10
  num_workers: 10
  push_delta: 5.0

  criterion:
    CeLoss:  # will be used if (abstain_class == False)
      loss_weight: 0
      reduction: 'mean'
    CeLossAbstain:  # will be used if (abstain_class == True)
        loss_weight: 0
        ab_weight: 0.3
        ab_logitpath: 'joined'
        reduction: 'mean'
    MSELoss:
      loss_weight: 0.1
      reduction: 'mean'
    MAELoss:
      loss_weight: 0.0
      reduction: 'mean'
    ClusterRoiReg:
      loss_weight: 10.0
      class_specific: True
      delta: 5.0
      kmin: 3
    PSDRoiFeat:
      loss_weight: 30.0
    ProtoDecorelation:
      loss_weight: 0.1
      class_specific: True
      delta: 5.0
      kmin: 1
    OrthogonalityLoss:
      loss_weight: 0.0
      mode: 'per_class'  # to encourage diversity in each class ('per_class'), or overal ('all')
    L2_LVloss:
      loss_weight: 0.0
      reduction: 'mean'
    Lnorm_occurrence:
      p: 2
      loss_weight: 0.0001 # 1e-4
      reduction: 'mean'
    trans_occurrence:
      loss_weight: 0.0 # 1e-4 must add only if you have affine transformation.
      reduction: 'mean'
    Lnorm_FC:
      p: 1
      loss_weight: 0.0 # 1e-4

  optimizer: &optimizer
    name: 'Adam'
    mode: 'lr_disjoint'  # can be lr_same/lr_disjoint
    lr: 0.001  # 1e-4
    lr_disjoint:
      cnn_backbone: 0.1 # 1e-4,
      add_on_layers: 0.1 # 1e-3
      occurrence_module: 0.1 # 1e-3
      prototype_vectors: 3 # 1e-3
      last_layer: 0.1 # 1e-4,
    lr_last_layer_only: 0.001 # 1e-6

  lr_schedule: &lr_schedule   # for joint_optimizer only
    name: 'ReduceLROnPlateau' # one of ReduceLROnPlateau, StepLR, CosineAnnealingLR
    StepLR:
      step_size: 5
      gamma: 0.5
    ReduceLROnPlateau:
      mode: 'max'  # used for R2 score
      factor: 0.5  # Factor by which the learning rate will be reduced
      patience: 5 # Number of epochs with no improvement after which learning rate will be reduced
      threshold: 0.0001  # Threshold for measuring the new optimum, to only focus on significant changes
      cooldown: 2
      min_lr: 0.000001  # 1e-6
    CosineAnnealingLR:
      eta_min: 0.000001  # 1e-6
#################### Data information #######################
data: &data 
  name: ef
  csv_file: 'data/echonet/data.csv'
  dataset_path: '/echonet'
  sample_size: null
  sampler: 'EF'  # one of "EF", "random"
  label_strings: null
  label_scheme_name: 'ef_2class'  # one of 'ef_2class', 'ef_4class', "ef_10class", or 'ef_regression'
  modes:  ["TRAIN", "VAL", "TEST", "TRAIN_push"]
  augmentation: True
  img_size: 112
  frames: 64  # 1 for image-based, 2 or more for video-based
  sample_period: 1
  use_seg_labels: True
  patch_width: 14
  test_type: 'all' # 3clip or all, singleclip
  max_clips: 10
